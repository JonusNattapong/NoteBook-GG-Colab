# NoteBook-GG-Colab

Collection of Google Colab Notebooks for various topics.

## Available Notebooks

| Title | Category | Description | Last Updated | Article | Colab |
|-------|----------|-------------|--------------|---------|-------|
| üßê LLM AutoEval | Tools | Evaluate your LLMs automatically using RunPod | 2025-01-18 |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing) |
| ü•± LazyMergekit | Tools | Merge models effortlessly using MergeKit with a single click | 2025-01-18 |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing) |
| ü¶é LazyAxolotl | Tools | Fine-tune models in the cloud with Axolotl in just one click | 2025-01-18 |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing) |
| ‚ö° AutoQuant | Tools | Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click | 2025-01-18 |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing) |
| üå≥ Model Family Tree | Tools | Visualize the lineage of merged models | 2025-01-18 |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing) |
| üöÄ ZeroSpace | Tools | Instantly create a Gradio chat interface using a free ZeroGPU | 2025-01-18 |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC) |
| Fine-tune Llama 3.1 with Unsloth | Fine-tuning | Perform ultra-efficient supervised fine-tuning in Google Colab | 2025-01-18 | [Article](https://originshq.com/blog/fine-tune-llama-3-1-ultra-efficiently-with-unsloth/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z?usp=sharing) |
| Fine-tune Llama 3 with ORPO | Fine-tuning | Achieve cheaper and faster fine-tuning in a single stage with ORPO | 2025-01-18 | [Article](https://originshq.com/blog/fine-tune-llama-3-with-orpo/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi) |
| Fine-tune Mistral-7b with DPO | Fine-tuning | Enhance the performance of supervised fine-tuned models using DPO | 2025-01-18 | [Article](https://originshq.com/blog/boost-the-performance-of-supervised-fine-tuned-models-with-dpo/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing) |
| Fine-tune Mistral-7b with QLoRA | Fine-tuning | Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL | 2025-01-18 |  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing) |
| Fine-tune CodeLlama using Axolotl | Fine-tuning | A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool | 2025-01-18 | [Article](https://originshq.com/blog/end-to-end-guide-to-the-state-of-the-art-tool-for-fine-tuning/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Xu0BrCB7IShwSWKVcfAfhehwjDrDMH5m?usp=sharing) |
| Fine-tune Llama 2 with QLoRA | Fine-tuning | A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab | 2025-01-18 | [Article](https://originshq.com/blog/step-by-step-guide-to-supervised-fine-tune-llama-2-in-google-colab/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing) |
| Introduction to Quantization | Quantization | An overview of optimizing large language models using 8-bit quantization | 2025-01-18 | [Article](https://originshq.com/blog/introduction-to-weight-quantization/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1DPr4mUQ92Cc-xf4GgAaB6dFcFnWIvqYi?usp=sharing) |
| 4-bit Quantization using GPTQ | Quantization | Learn to quantize your open-source LLMs for consumer hardware using GPTQ | 2025-01-18 | [Article](https://originshq.com/blog/4-bit-llm-quantization-with-gptq/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A?usp=sharing) |
| Quantization with GGUF and llama.cpp | Quantization | Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub | 2025-01-18 | [Article](https://originshq.com/blog/quantize-llama-models-with-gguf-and-llama-cpp/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing) |
| ExLlamaV2: The Fastest Library to Run LLMs | Quantization | Quantize and run EXL2 models, then upload them to the HF Hub | 2025-01-18 | [Article](https://originshq.com/blog/exllamav2-the-fastest-library-to-run-llms/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing) |
| Merge LLMs with MergeKit | Other | Easily create your own models without needing a GPU | 2025-01-18 | [Article](https://originshq.com/blog/merge-large-language-models-with-mergekit/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing) |
| Create MoEs with MergeKit | Other | Combine multiple experts into a single frankenMoE | 2025-01-18 | [Article](https://originshq.com/blog/create-mixtures-of-experts-with-mergekit/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing) |
| Uncensor any LLM with abliteration | Other | Fine-tuning strategies without retraining the model | 2025-01-18 | [Article](https://originshq.com/blog/uncensor-any-llm-with-abliteration/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR?usp=sharing) |
| Improve ChatGPT with Knowledge Graphs | Other | Augment ChatGPT's responses using knowledge graphs | 2025-01-18 | [Article](https://originshq.com/blog/improve-chatgpt-with-knowledge-graphs/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing) |
| Decoding Strategies in Large Language Models | Other | A comprehensive guide covering text generation methods from beam search to nucleus sampling | 2025-01-18 | [Article](https://originshq.com/blog/decoding-strategies-in-large-language-models/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing) |

## Categories


### Fine-tuning
- Fine-tune Llama 3.1 with Unsloth
  - Article: [Fine-tune Llama 3.1 with Unsloth](https://originshq.com/blog/fine-tune-llama-3-1-ultra-efficiently-with-unsloth/)
  - Tags: llama, fine-tuning, unsloth
- Fine-tune Llama 3 with ORPO
  - Article: [Fine-tune Llama 3 with ORPO](https://originshq.com/blog/fine-tune-llama-3-with-orpo/)
  - Tags: llama, fine-tuning, orpo
- Fine-tune Mistral-7b with DPO
  - Article: [Fine-tune Mistral-7b with DPO](https://originshq.com/blog/boost-the-performance-of-supervised-fine-tuned-models-with-dpo/)
  - Tags: mistral, fine-tuning, dpo
- Fine-tune Mistral-7b with QLoRA
  - Tags: mistral, fine-tuning, qlora, trl
- Fine-tune CodeLlama using Axolotl
  - Article: [Fine-tune CodeLlama using Axolotl](https://originshq.com/blog/end-to-end-guide-to-the-state-of-the-art-tool-for-fine-tuning/)
  - Tags: codellama, fine-tuning, axolotl
- Fine-tune Llama 2 with QLoRA
  - Article: [Fine-tune Llama 2 with QLoRA](https://originshq.com/blog/step-by-step-guide-to-supervised-fine-tune-llama-2-in-google-colab/)
  - Tags: llama, fine-tuning, qlora

### Other
- Merge LLMs with MergeKit
  - Article: [Merge LLMs with MergeKit](https://originshq.com/blog/merge-large-language-models-with-mergekit/)
  - Tags: model-merging, mergekit, no-gpu
- Create MoEs with MergeKit
  - Article: [Create MoEs with MergeKit](https://originshq.com/blog/create-mixtures-of-experts-with-mergekit/)
  - Tags: model-merging, mergekit, moe
- Uncensor any LLM with abliteration
  - Article: [Uncensor any LLM with abliteration](https://originshq.com/blog/uncensor-any-llm-with-abliteration/)
  - Tags: uncensor, abliteration, fine-tuning
- Improve ChatGPT with Knowledge Graphs
  - Article: [Improve ChatGPT with Knowledge Graphs](https://originshq.com/blog/improve-chatgpt-with-knowledge-graphs/)
  - Tags: chatgpt, knowledge-graphs, augmentation
- Decoding Strategies in Large Language Models
  - Article: [Decoding Strategies in Large Language Models](https://originshq.com/blog/decoding-strategies-in-large-language-models/)
  - Tags: decoding, beam-search, nucleus-sampling

### Quantization
- Introduction to Quantization
  - Article: [Introduction to Quantization](https://originshq.com/blog/introduction-to-weight-quantization/)
  - Tags: quantization, 8-bit, optimization
- 4-bit Quantization using GPTQ
  - Article: [4-bit Quantization using GPTQ](https://originshq.com/blog/4-bit-llm-quantization-with-gptq/)
  - Tags: quantization, 4-bit, gptq
- Quantization with GGUF and llama.cpp
  - Article: [Quantization with GGUF and llama.cpp](https://originshq.com/blog/quantize-llama-models-with-gguf-and-llama-cpp/)
  - Tags: llama, quantization, gguf, llama.cpp
- ExLlamaV2: The Fastest Library to Run LLMs
  - Article: [ExLlamaV2: The Fastest Library to Run LLMs](https://originshq.com/blog/exllamav2-the-fastest-library-to-run-llms/)
  - Tags: exllama, quantization, optimization

### Tools
- üßê LLM AutoEval
  - Tags: evaluation, llm, runpod
- ü•± LazyMergekit
  - Tags: model-merging, mergekit, llm
- ü¶é LazyAxolotl
  - Tags: fine-tuning, axolotl, cloud
- ‚ö° AutoQuant
  - Tags: quantization, gguf, gptq, exl2, awq, hqq
- üå≥ Model Family Tree
  - Tags: visualization, model-merging, genealogy
- üöÄ ZeroSpace
  - Tags: gradio, chat-interface, deployment

---
Last updated: 2025-02-24 22:36:15