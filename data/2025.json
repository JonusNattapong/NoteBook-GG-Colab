{
  "notebooks": [
    {
      "title": "üßê LLM AutoEval",
      "description": "Evaluate your LLMs automatically using RunPod.",
      "category": "Tools",
      "tags": [
        "llm"
      ],
      "lastUpdated": "2025-01-18",
      "colabLink": "https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing",
      "articleLink": ""
    },
    {
      "title": "ü•± LazyMergekit",
      "description": "Merge models effortlessly using MergeKit with a single click.",
      "category": "Tools",
      "tags": [
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "colabLink": "https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing",
      "articleLink": ""
    },
    {
      "title": "ü¶é LazyAxolotl",
      "description": "Fine-tune models in the cloud with Axolotl in just one click.",
      "category": "Tools",
      "tags": [
        "fine-tuning",
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "colabLink": "https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing",
      "articleLink": ""
    },
    {
      "title": "‚ö° AutoQuant",
      "description": "Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click.",
      "category": "Tools",
      "tags": [
        "quantization",
        "llm"
      ],
      "lastUpdated": "2025-01-18",
      "colabLink": "https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing",
      "articleLink": ""
    },
    {
      "title": "üå≥ Model Family Tree",
      "description": "Visualize the lineage of merged models.",
      "category": "Tools",
      "tags": [
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "colabLink": "https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing",
      "articleLink": ""
    },
    {
      "title": "üöÄ ZeroSpace",
      "description": "Instantly create a Gradio chat interface using a free ZeroGPU.",
      "category": "Tools",
      "tags": [],
      "lastUpdated": "2025-01-18",
      "colabLink": "https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC",
      "articleLink": ""
    },
    {
      "title": "Fine-tune Llama 3.1 with Unsloth",
      "description": "Perform ultra-efficient supervised fine-tuning in Google Colab.",
      "category": "Fine-tuning",
      "tags": [
        "fine-tuning"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/fine-tune-llama-3-1-ultra-efficiently-with-unsloth/",
      "colabLink": "https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z?usp=sharing"
    },
    {
      "title": "Fine-tune Llama 3 with ORPO",
      "description": "Achieve cheaper and faster fine-tuning in a single stage with ORPO.",
      "category": "Fine-tuning",
      "tags": [
        "fine-tuning"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/fine-tune-llama-3-with-orpo/",
      "colabLink": "https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi"
    },
    {
      "title": "Fine-tune Mistral-7b with DPO",
      "description": "Enhance the performance of supervised fine-tuned models using DPO.",
      "category": "Fine-tuning",
      "tags": [
        "fine-tuning",
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/boost-the-performance-of-supervised-fine-tuned-models-with-dpo/",
      "colabLink": "https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing"
    },
    {
      "title": "Fine-tune Mistral-7b with QLoRA",
      "description": "Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL.",
      "category": "Fine-tuning",
      "tags": [
        "fine-tuning"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "",
      "colabLink": "https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing"
    },
    {
      "title": "Fine-tune CodeLlama using Axolotl",
      "description": "A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool.",
      "category": "Fine-tuning",
      "tags": [
        "fine-tuning"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/end-to-end-guide-to-the-state-of-the-art-tool-for-fine-tuning/",
      "colabLink": "https://colab.research.google.com/drive/1Xu0BrCB7IShwSWKVcfAfhehwjDrDMH5m?usp=sharing"
    },
    {
      "title": "Fine-tune Llama 2 with QLoRA",
      "description": "A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab.",
      "category": "Fine-tuning",
      "tags": [
        "fine-tuning"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/step-by-step-guide-to-supervised-fine-tune-llama-2-in-google-colab/",
      "colabLink": "https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing"
    },
    {
      "title": "Introduction to Quantization",
      "description": "An overview of optimizing large language models using 8-bit quantization.",
      "category": "Quantization",
      "tags": [
        "quantization",
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/introduction-to-weight-quantization/",
      "colabLink": "https://colab.research.google.com/drive/1DPr4mUQ92Cc-xf4GgAaB6dFcFnWIvqYi?usp=sharing"
    },
    {
      "title": "4-bit Quantization using GPTQ",
      "description": "Learn to quantize your open-source LLMs for consumer hardware using GPTQ.",
      "category": "Quantization",
      "tags": [
        "quantization",
        "llm"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/4-bit-llm-quantization-with-gptq/",
      "colabLink": "https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A?usp=sharing"
    },
    {
      "title": "Quantization with GGUF and llama.cpp",
      "description": "Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub.",
      "category": "Quantization",
      "tags": [
        "quantization",
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/quantize-llama-models-with-gguf-and-llama-cpp/",
      "colabLink": "https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing"
    },
    {
      "title": "ExLlamaV2: The Fastest Library to Run LLMs",
      "description": "Quantize and run EXL2 models, then upload them to the HF Hub.",
      "category": "Quantization",
      "tags": [
        "quantization",
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/exllamav2-the-fastest-library-to-run-llms/",
      "colabLink": "https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing"
    },
    {
      "title": "Merge LLMs with MergeKit",
      "description": "Easily create your own models without needing a GPU.",
      "category": "Other",
      "tags": [
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/merge-large-language-models-with-mergekit/",
      "colabLink": "https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing"
    },
    {
      "title": "Create MoEs with MergeKit",
      "description": "Combine multiple experts into a single frankenMoE.",
      "category": "Other",
      "tags": [],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/create-mixtures-of-experts-with-mergekit/",
      "colabLink": "https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing"
    },
    {
      "title": "Uncensor any LLM with abliteration",
      "description": "Fine-tuning strategies without retraining the model.",
      "category": "Other",
      "tags": [
        "fine-tuning",
        "model"
      ],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/uncensor-any-llm-with-abliteration/",
      "colabLink": "https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR?usp=sharing"
    },
    {
      "title": "Improve ChatGPT with Knowledge Graphs",
      "description": "Augment ChatGPT‚Äôs responses using knowledge graphs.",
      "category": "Other",
      "tags": [],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/improve-chatgpt-with-knowledge-graphs/",
      "colabLink": "https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing"
    },
    {
      "title": "Decoding Strategies in Large Language Models",
      "description": "A comprehensive guide covering text generation methods from beam search to nucleus sampling.",
      "category": "Other",
      "tags": [],
      "lastUpdated": "2025-01-18",
      "articleLink": "https://originshq.com/blog/decoding-strategies-in-large-language-models/",
      "colabLink": "https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing"
    }
  ]
}