{
  "notebooks": [
    {
      "title": "üßê LLM AutoEval",
      "description": "Evaluate your LLMs automatically using RunPod",
      "colabLink": "https://colab.research.google.com/drive/1Igs3WZuXAIv9X0vwqiE90QlEPys8e8Oa?usp=sharing",
      "category": "Tools",
      "tags": ["evaluation", "llm", "runpod"],
      "articleLink": "",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "ü•± LazyMergekit",
      "description": "Merge models effortlessly using MergeKit with a single click",
      "colabLink": "https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing",
      "category": "Tools",
      "tags": ["model-merging", "mergekit", "llm"],
      "articleLink": "",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "ü¶é LazyAxolotl",
      "description": "Fine-tune models in the cloud with Axolotl in just one click",
      "colabLink": "https://colab.research.google.com/drive/1TsDKNo2riwVmU55gjuBgB1AXVtRRfRHW?usp=sharing",
      "category": "Tools",
      "tags": ["fine-tuning", "axolotl", "cloud"],
      "articleLink": "",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "‚ö° AutoQuant",
      "description": "Quantize LLMs into GGUF, GPTQ, EXL2, AWQ, and HQQ formats in one click",
      "colabLink": "https://colab.research.google.com/drive/1b6nqC7UZVt8bx4MksX7s656GXPM-eWw4?usp=sharing",
      "category": "Tools",
      "tags": ["quantization", "gguf", "gptq", "exl2", "awq", "hqq"],
      "articleLink": "",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "üå≥ Model Family Tree",
      "description": "Visualize the lineage of merged models",
      "colabLink": "https://colab.research.google.com/drive/1s2eQlolcI1VGgDhqWIANfkfKvcKrMyNr?usp=sharing",
      "category": "Tools",
      "tags": ["visualization", "model-merging", "genealogy"],
      "articleLink": "",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "üöÄ ZeroSpace",
      "description": "Instantly create a Gradio chat interface using a free ZeroGPU",
      "colabLink": "https://colab.research.google.com/drive/1LcVUW5wsJTO2NGmozjji5CkC--646LgC",
      "category": "Tools",
      "tags": ["gradio", "chat-interface", "deployment"],
      "articleLink": "",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Fine-tune Llama 3.1 with Unsloth",
      "description": "Perform ultra-efficient supervised fine-tuning in Google Colab",
      "colabLink": "https://colab.research.google.com/drive/164cg_O7SV7G8kZr_JXqLd6VC7pd86-1Z?usp=sharing",
      "category": "Fine-tuning",
      "tags": ["llama", "fine-tuning", "unsloth"],
      "articleLink": "https://originshq.com/blog/fine-tune-llama-3-1-ultra-efficiently-with-unsloth/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Fine-tune Llama 3 with ORPO",
      "description": "Achieve cheaper and faster fine-tuning in a single stage with ORPO",
      "colabLink": "https://colab.research.google.com/drive/1eHNWg9gnaXErdAa8_mcvjMupbSS6rDvi",
      "category": "Fine-tuning",
      "tags": ["llama", "fine-tuning", "orpo"],
      "articleLink": "https://originshq.com/blog/fine-tune-llama-3-with-orpo/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Fine-tune Mistral-7b with DPO",
      "description": "Enhance the performance of supervised fine-tuned models using DPO",
      "colabLink": "https://colab.research.google.com/drive/15iFBr1xWgztXvhrj5I9fBv20c7CFOPBE?usp=sharing",
      "category": "Fine-tuning",
      "tags": ["mistral", "fine-tuning", "dpo"],
      "articleLink": "https://originshq.com/blog/boost-the-performance-of-supervised-fine-tuned-models-with-dpo/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Fine-tune Mistral-7b with QLoRA",
      "description": "Supervised fine-tuning of Mistral-7b in a free-tier Google Colab using TRL",
      "colabLink": "https://colab.research.google.com/drive/1o_w0KastmEJNVwT5GoqMCciH-18ca5WS?usp=sharing",
      "category": "Fine-tuning",
      "tags": ["mistral", "fine-tuning", "qlora", "trl"],
      "articleLink": "",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Fine-tune CodeLlama using Axolotl",
      "description": "A comprehensive guide to fine-tune with the state-of-the-art Axolotl tool",
      "colabLink": "https://colab.research.google.com/drive/1Xu0BrCB7IShwSWKVcfAfhehwjDrDMH5m?usp=sharing",
      "category": "Fine-tuning",
      "tags": ["codellama", "fine-tuning", "axolotl"],
      "articleLink": "https://originshq.com/blog/end-to-end-guide-to-the-state-of-the-art-tool-for-fine-tuning/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Fine-tune Llama 2 with QLoRA",
      "description": "A step-by-step guide to supervised fine-tuning of Llama 2 in Google Colab",
      "colabLink": "https://colab.research.google.com/drive/1PEQyJO1-f6j0S_XJ8DV50NkpzasXkrzd?usp=sharing",
      "category": "Fine-tuning",
      "tags": ["llama", "fine-tuning", "qlora"],
      "articleLink": "https://originshq.com/blog/step-by-step-guide-to-supervised-fine-tune-llama-2-in-google-colab/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Introduction to Quantization",
      "description": "An overview of optimizing large language models using 8-bit quantization",
      "colabLink": "https://colab.research.google.com/drive/1DPr4mUQ92Cc-xf4GgAaB6dFcFnWIvqYi?usp=sharing",
      "category": "Quantization",
      "tags": ["quantization", "8-bit", "optimization"],
      "articleLink": "https://originshq.com/blog/introduction-to-weight-quantization/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "4-bit Quantization using GPTQ",
      "description": "Learn to quantize your open-source LLMs for consumer hardware using GPTQ",
      "colabLink": "https://colab.research.google.com/drive/1lSvVDaRgqQp_mWK_jC9gydz6_-y6Aq4A?usp=sharing",
      "category": "Quantization",
      "tags": ["quantization", "4-bit", "gptq"],
      "articleLink": "https://originshq.com/blog/4-bit-llm-quantization-with-gptq/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Quantization with GGUF and llama.cpp",
      "description": "Quantize Llama 2 models with llama.cpp and upload their GGUF versions to the HF Hub",
      "colabLink": "https://colab.research.google.com/drive/1pL8k7m04mgE5jo2NrjGi8atB0j_37aDD?usp=sharing",
      "category": "Quantization",
      "tags": ["llama", "quantization", "gguf", "llama.cpp"],
      "articleLink": "https://originshq.com/blog/quantize-llama-models-with-gguf-and-llama-cpp/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "ExLlamaV2: The Fastest Library to Run LLMs",
      "description": "Quantize and run EXL2 models, then upload them to the HF Hub",
      "colabLink": "https://colab.research.google.com/drive/1yrq4XBlxiA0fALtMoT2dwiACVc77PHou?usp=sharing",
      "category": "Quantization",
      "tags": ["exllama", "quantization", "optimization"],
      "articleLink": "https://originshq.com/blog/exllamav2-the-fastest-library-to-run-llms/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Merge LLMs with MergeKit",
      "description": "Easily create your own models without needing a GPU",
      "colabLink": "https://colab.research.google.com/drive/1_JS7JKJAQozD48-LhYdegcuuZ2ddgXfr?usp=sharing",
      "category": "Other",
      "tags": ["model-merging", "mergekit", "no-gpu"],
      "articleLink": "https://originshq.com/blog/merge-large-language-models-with-mergekit/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Create MoEs with MergeKit",
      "description": "Combine multiple experts into a single frankenMoE",
      "colabLink": "https://colab.research.google.com/drive/1obulZ1ROXHjYLn6PPZJwRR6GzgQogxxb?usp=sharing",
      "category": "Other",
      "tags": ["model-merging", "mergekit", "moe"],
      "articleLink": "https://originshq.com/blog/create-mixtures-of-experts-with-mergekit/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Uncensor any LLM with abliteration",
      "description": "Fine-tuning strategies without retraining the model",
      "colabLink": "https://colab.research.google.com/drive/1VYm3hOcvCpbGiqKZb141gJwjdmmCcVpR?usp=sharing",
      "category": "Other",
      "tags": ["uncensor", "abliteration", "fine-tuning"],
      "articleLink": "https://originshq.com/blog/uncensor-any-llm-with-abliteration/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Improve ChatGPT with Knowledge Graphs",
      "description": "Augment ChatGPT's responses using knowledge graphs",
      "colabLink": "https://colab.research.google.com/drive/1mwhOSw9Y9bgEaIFKT4CLi0n18pXRM4cj?usp=sharing",
      "category": "Other",
      "tags": ["chatgpt", "knowledge-graphs", "augmentation"],
      "articleLink": "https://originshq.com/blog/improve-chatgpt-with-knowledge-graphs/",
      "lastUpdated": "2025-01-18"
    },
    {
      "title": "Decoding Strategies in Large Language Models",
      "description": "A comprehensive guide covering text generation methods from beam search to nucleus sampling",
      "colabLink": "https://colab.research.google.com/drive/19CJlOS5lI29g-B3dziNn93Enez1yiHk2?usp=sharing",
      "category": "Other",
      "tags": ["decoding", "beam-search", "nucleus-sampling"],
      "articleLink": "https://originshq.com/blog/decoding-strategies-in-large-language-models/",
      "lastUpdated": "2025-01-18"
    }
  ]
}
